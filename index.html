<!DOCTYPE html>
<html lang="en">

<head>
    <title></title>
    
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
    <meta name="robots" content="noodp"/>

    <link rel="stylesheet" href="https://saskapult.github.io/style.css">
    <link rel="stylesheet" href="https://saskapult.github.io/color/green.css">

        <link rel="stylesheet" href="https://saskapult.github.io/color/background_auto.css">
    
    <link rel="stylesheet" href="https://saskapult.github.io/font-hack-subset.css">

    <meta name="description" content="">

    <meta property="og:description" content="">
    <meta property="og:title" content="">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://saskapult.github.io/">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:description" content="">
    <meta name="twitter:title" content="">
    <meta property="twitter:domain" content="saskapult.github.io">
    <meta property="twitter:url" content="https://saskapult.github.io/">

        <link rel="shortcut icon" type="image/png" href="/wei.png">
    
    </head>

<body class="">
<div class="container">
    
    <header class="header">
        <div class="header__inner">
            <div class="header__logo">
                    
                <a href="https://saskapult.github.io" style="text-decoration: none;">
                    <div class="logo">
                      
                            K Smith
                        
                    </div>
                </a>
            </div>
        </div>

        
        
                <nav class="menu">
            <ul class="menu__inner">
                <li class="active"><a href="https://saskapult.github.io">posts</a></li>
            
                <li><a href="https://saskapult.github.io/archive">archive</a></li>
            
                <li><a href="https://saskapult.github.io/tags">tags</a></li>
            
                <li><a href="https://saskapult.github.io/resume">resume</a></li>
            
                <li><a href="https://saskapult.github.io/about">about me</a></li>
            
                <li><a href="https://github.com/Saskapult" target="_blank" rel="noopener noreferrer">github</a></li>
            </ul>
        </nav>
    
    
        
    </header>
    

    <div class="content">
        
        <div class="posts">
                <div class="post on-list">
                    
    <h1 class="post-title"><a href="https://saskapult.github.io/ego-search/">EGO Search</a></h1>
    <div class="post-meta-inline">
        
    <span class="post-date">
            2025-10-06
        </span>

    </div>

    
        <span class="post-tags-inline">
                :: tags:&nbsp;
                <a class="post-tag" href="https://saskapult.github.io/tags/project/">#project</a></span>
    


                    <div class="post-content">
            <!-- Context -->
<p>I've been working with retrieval augmented generation (RAG) as part of my job.
While I can't go too much into detail, we're generating a knowledge base by feeding an LLM a bunch of pieces of text and then use that knowledge base to answer queries.
Except in a fancy way that I should not talk about here.
Anyway, it uses an LLM for a lot of that.
Having a ten-year-old laptop, it's not something that I'm in a position to run locally.
And even if I could, that's still an entire LLM we're talking about.
I do not want to pay for the electricity to run that!</p>
<!-- Explain vector RAG -->
<p>A few applications of what we're doing amount to little more than a search through a text, albeit a smart search through a text.
One method for doing that is with the use of vector RAG.
This utilizes a part of an LLM known as an embedding model.
This is the "encoder" part of an LLM and in GPT-style models it is significantly smaller than the "decoder" part.
The embedding model transforms text into a vector, a collection of numbers in some ridiculously high-dimensional space.
Semantically similar texts generate vectors that are "close" to one another.
We can use cosine similarity to measure this!</p>
<p>$a \cdot b = |a| |b| \cos(\theta)$</p>
<p>What we want here is the $\theta$ value because that will tell us the angle between our two vectors.
If it's low then they're probably similar, and if it's high they're probably unrelated.
An embedding for "cats like catnip" would (hopefully) be similar to "what do cats like" and thus we can use this technique to retrieve relevant information for a query.</p>
<!-- The point! -->
<p>This works quite well when text is broken into sufficiently-sized segments, but two questions arise:</p>
<ul>
<li>What if something is split across the boundaries of these segments?</li>
<li>What if we make the segments really really small?</li>
</ul>
<p>This is the part of the article where I introduce <a href="https://github.com/Saskapult/iiqe">Embedding Group Overlap (EGO) Search</a>!
EGO search breaks a text into segments, constructs groups from those segments, scores those segments using embedding cosine similarity, and then finds the segments with the highest score across their member groups.</p>
<!-- Example -->
<p>Let's have an example!
You have the collection of sentences "now for something completely different," "things I like to bake," "cake is one thing," and "oh also cats are nice."
We generate some groups from these segments.
In this minimal example those are "now for something completely different things I like to bake," "things I like to bake cake is one thing" and "cake is one thing oh also cats are nice."
We generate embeddings for those and an embedding for a query text like "do I like to bake cake?"
Groups 1 and 2 score most highly in this, so segment 2 receives a very high score because it appears in both of those groups.</p>

  <figure class="center" >
    <img src="/ego-search/sentence_level.png" style="width: 100%;" decoding="async" loading="lazy"/>
    
      <figcaption class="center" style="font-style: italic;"><p>A similarity graph for some sentences in some text.</p>
</figcaption>
    
  </figure>

<p>Once we've scored the segments, we identify peaks in the score values.
We then descend the peak to some cutoff value (in the graph example the 65th percentile) to identify "regions" of text similar to the query text.
The algorithm outputs a list of these regions sorted by their peak score (though one could use other metrics, I just haven't tried that yet).</p>
<p>A neat property of this is that a "segment" can be smaller than a sentence!
For my demo I ran EGO Search with sentence-level segments and then ran it again at a word level on the resulting region.
It works pretty well!
It's also, like, the main innovation of this work so I'd sure hope that it works pretty well.</p>

  <figure class="center" >
    <img src="/ego-search/word_level.png" style="width: 100%;" decoding="async" loading="lazy"/>
    
      <figcaption class="center" style="font-style: italic;"><p>A similarity graph for some words in some text.</p>
</figcaption>
    
  </figure>

<!-- Efficiency -->
<p>So is it efficient?
Hahaha... <a href="https://i.kym-cdn.com/photos/images/newsfeed/000/549/301/119.jpg">no</a>.
There is a lot of redundant computation in the "overlap" part of the EGO Search.
Indexing a document takes a lot of processing power!
That only needs to be done once, but we're still relying on cosine similarity for each query.
I'm sure that you can find a more efficient way to search through a document!</p>
<!-- Conclusion -->
<p>EGO Search uses text embeddings to retrieve information at a scalable resolution.
It's able to retrieve semantically-relevant parts of a text and their surrounding context without the computational price of a full LLM.
Is it particularly well-suited to that task?
Probably not!
But I think it's pretty neat :).
I've made a poster for it and I'll be presenting it at the ACM Celebration of Cascadia Women in Computing 2025 Student Poster session.</p>
<p>(well if they let me in, we don't know for sure yet.)</p>

  <figure class="center" >
    <img src="/ego-search/poster.png" style="width: 100%;" decoding="async" loading="lazy"/>
    
      <figcaption class="center" style="font-style: italic;"><p>My poster!</p>
</figcaption>
    
  </figure>

<p>(yes I did consider using the "G" in EGO Search for "Godzilla" instead of "Group" and while that would have been cooler it would've made less sense)</p>

        </div>

                </div>
            
                <div class="post on-list">
                    
    <h1 class="post-title"><a href="https://saskapult.github.io/lerp3/">3D Noise Scaling</a></h1>
    <div class="post-meta-inline">
        
    <span class="post-date">
            2025-02-07
        </span>

    </div>

    
        <span class="post-tags-inline">
                :: tags:&nbsp;
                <a class="post-tag" href="https://saskapult.github.io/tags/hobby/">#hobby</a></span>
    


                    <div class="post-content">
            <p>Prior to beta 1.8, Minecraft had a particular style of terrain that appeals to me greatly.
There are many factors that contribute to this.
Low movement speed, high rates of weirdness, and chaotic biome placement are all important factors in the experience.</p>
<p>While developing Pinefruit, I wanted to recreate the experience of old Minecraft terrain.
As a first step I needed to generate the shape of the terrain itself.
There are <a href="https://www.youtube.com/watch?v=CSa5O6knuwI">many factors</a> that go into generating Minecraft's terrain.
A key aspect that is often overlooked, however, is the blockiness of the density noise used to determine the surface's shape.</p>
<p><img src="https://saskapult.github.io/lerp3/blocky0.png" alt="" /></p>
<p>Here we can see a valley between two hills.
What I'd like for you to notice is that the hills are kind of square looking.</p>
<p><img src="https://saskapult.github.io/lerp3/blocky1.png" alt="" /></p>
<p>We can see it more clearly here.
It's neat.
It's blocky.
It has a distinctive look to it.
But why is it that way and how can we recreate it?</p>
<p>I'm not good at dramatic buildup.
It's a product of 3d noise interpolation.
Minecraft interpolates its density noise, presumably in an attempt to reduce computational load.
It's just an extension of linear interpolation into 3d.</p>
<pre data-lang="rust" style="background-color:#1e1e1e;color:#dcdcdc;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#569cd6;">fn </span><span>lerp(x: </span><span style="color:#569cd6;">f32</span><span>, x1: </span><span style="color:#569cd6;">f32</span><span>, x2: </span><span style="color:#569cd6;">f32</span><span>, q00: </span><span style="color:#569cd6;">f32</span><span>, q01: </span><span style="color:#569cd6;">f32</span><span>) -&gt; </span><span style="color:#569cd6;">f32 </span><span>{
</span><span>	((x2 - x) / (x2 - x1)) * q00 + ((x - x1) / (x2 - x1)) * q01
</span><span>}
</span><span style="color:#569cd6;">fn </span><span>lerp3(
</span><span>	x: </span><span style="color:#569cd6;">f32</span><span>, y: </span><span style="color:#569cd6;">f32</span><span>, z: </span><span style="color:#569cd6;">f32</span><span>, 
</span><span>	q000: </span><span style="color:#569cd6;">f32</span><span>, q001: </span><span style="color:#569cd6;">f32</span><span>, q010: </span><span style="color:#569cd6;">f32</span><span>, q011: </span><span style="color:#569cd6;">f32</span><span>, q100: </span><span style="color:#569cd6;">f32</span><span>, q101: </span><span style="color:#569cd6;">f32</span><span>, q110: </span><span style="color:#569cd6;">f32</span><span>, q111: </span><span style="color:#569cd6;">f32</span><span>, 
</span><span>	x1: </span><span style="color:#569cd6;">f32</span><span>, x2: </span><span style="color:#569cd6;">f32</span><span>, y1: </span><span style="color:#569cd6;">f32</span><span>, y2: </span><span style="color:#569cd6;">f32</span><span>, z1: </span><span style="color:#569cd6;">f32</span><span>, z2: </span><span style="color:#569cd6;">f32</span><span>, 
</span><span>) -&gt; </span><span style="color:#569cd6;">f32 </span><span>{
</span><span>	</span><span style="color:#569cd6;">let</span><span> x00 = lerp(x, x1, x2, q000, q100);
</span><span>	</span><span style="color:#569cd6;">let</span><span> x10 = lerp(x, x1, x2, q010, q110);
</span><span>	</span><span style="color:#569cd6;">let</span><span> x01 = lerp(x, x1, x2, q001, q101);
</span><span>	</span><span style="color:#569cd6;">let</span><span> x11 = lerp(x, x1, x2, q011, q111);
</span><span>
</span><span>	</span><span style="color:#569cd6;">let</span><span> r0 = lerp(y, y1, y2, x00, x01);
</span><span>	</span><span style="color:#569cd6;">let</span><span> r1 = lerp(y, y1, y2, x10, x11);
</span><span>
</span><span>	lerp(z, z1, z2, r0, r1)
</span><span>}
</span></code></pre>
<!-- TODO: SHOW RESULT TERRAIN -->
<p>It's simple to add this to our terrain generator.
This works pretty well, but it's rather inefficient.
Scaling a 8x8x8 volume to 16x16x16 with this takes 114,564.06ns.
Just generating a 16x16x16 noise volume takes 113,809.63ns, which is (just barely) faster!</p>
<p>My first order of business was to refactor that <code>lerp3</code> code to reduce the number of divisions.
In the following code, the t values are the factor of each axis and the q values are the values at each octant.</p>
<pre data-lang="rust" style="background-color:#1e1e1e;color:#dcdcdc;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#569cd6;">fn </span><span>lerp(a: </span><span style="color:#569cd6;">f32</span><span>, b: </span><span style="color:#569cd6;">f32</span><span>, t: </span><span style="color:#569cd6;">f32</span><span>) -&gt; </span><span style="color:#569cd6;">f32 </span><span>{
</span><span>	a * (</span><span style="color:#b5cea8;">1.0 </span><span>- t) + b * t
</span><span>}
</span><span style="color:#569cd6;">fn </span><span>lerp3(
</span><span>	xt: </span><span style="color:#569cd6;">f32</span><span>, yt: </span><span style="color:#569cd6;">f32</span><span>, zt: </span><span style="color:#569cd6;">f32</span><span>, 
</span><span>	q000: </span><span style="color:#569cd6;">f32</span><span>, q001: </span><span style="color:#569cd6;">f32</span><span>, q010: </span><span style="color:#569cd6;">f32</span><span>, q011: </span><span style="color:#569cd6;">f32</span><span>, q100: </span><span style="color:#569cd6;">f32</span><span>, q101: </span><span style="color:#569cd6;">f32</span><span>, q110: </span><span style="color:#569cd6;">f32</span><span>, q111: </span><span style="color:#569cd6;">f32</span><span>, 
</span><span>) -&gt; </span><span style="color:#569cd6;">f32 </span><span>{
</span><span>	</span><span style="color:#569cd6;">let</span><span> x00 = lerp(q000, q100, xt);
</span><span>	</span><span style="color:#569cd6;">let</span><span> x10 = lerp(q010, q110, xt);
</span><span>	</span><span style="color:#569cd6;">let</span><span> x01 = lerp(q001, q101, xt);
</span><span>	</span><span style="color:#569cd6;">let</span><span> x11 = lerp(q011, q111, xt);
</span><span>	</span><span style="color:#569cd6;">let</span><span> r0 = lerp(x00, x01, zt);
</span><span>	</span><span style="color:#569cd6;">let</span><span> r1 = lerp(x10, x11, zt);
</span><span>	lerp(r0, r1, yt)
</span><span>}
</span></code></pre>
<p>This works pretty well.
Now we are doing the same task in 95,697.39ns.
For this application I only need to scale the noise by an integer factor, and this gives me some more opportunities for optimization.</p>
<p>I tried skipping noise interpolation at values where all t values will be zero.
When doubling the scale of a noise volume, this would reduce the work by 12.5%.
Oddly enough, this was a bad idea.
When scaling noise from 8x8x8 to 16x16x16, we experience a slowdown of nearly 14% (95,574.26ns vs 110,722.50ns).
That's not so great.</p>
<p>As another avenue, I realized that I could precompute the t values rather than computing them for each cell.
At the beginning of the function I create an array on the stack which stores the t values for a cell at offset <code>i</code> at index <code>i</code>.
When inside the loop, we can fetch the precomputed value instead of performing a floating-point division.</p>
<pre data-lang="rust" style="background-color:#1e1e1e;color:#dcdcdc;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#569cd6;">let mut</span><span> t_vals = [</span><span style="color:#b5cea8;">0.0</span><span>; </span><span style="color:#b4cea8;">MAX_SCALE</span><span>];
</span><span style="color:#569cd6;">for</span><span> i </span><span style="color:#569cd6;">in </span><span style="color:#b5cea8;">0</span><span style="color:#569cd6;">..</span><span>scale {
</span><span>	t_vals[i] = i </span><span style="color:#569cd6;">as f32 </span><span>/ scale </span><span style="color:#569cd6;">as f32</span><span>;
</span><span>}
</span><span>
</span><span style="color:#569cd6;">for</span><span> cell </span><span style="color:#569cd6;">in</span><span> cells {
</span><span>	</span><span style="color:#569cd6;">...
</span><span>	</span><span style="color:#569cd6;">let</span><span> d = cell - (cell / scale) * scale;
</span><span>	</span><span style="color:#569cd6;">let</span><span> xt = t_vals[</span><span style="color:#b5cea8;">0</span><span>][d.x </span><span style="color:#569cd6;">as usize</span><span>];
</span><span>	</span><span style="color:#569cd6;">let</span><span> yt = t_vals[</span><span style="color:#b5cea8;">1</span><span>][d.y </span><span style="color:#569cd6;">as usize</span><span>];
</span><span>	</span><span style="color:#569cd6;">let</span><span> zt = t_vals[</span><span style="color:#b5cea8;">2</span><span>][d.z </span><span style="color:#569cd6;">as usize</span><span>];
</span><span>	</span><span style="color:#569cd6;">...
</span><span>}
</span></code></pre>
<p>I used this code to generate 16x16x16 volumes of noise, analogous to a chunk in Minecraft.
Without interpolation the noise was generated in 109,302.56ns.
With interpolation scaling from 8x8x8, the noise was generated in 89,285.23ns.
That's a win, being 22% faster than without this optimization!</p>
<p>In the beginning we were generating noise volumes in 114,564.06ns, and now we are generating them in 89,285.23ns.
I've had fun optimizing this and my optimizations actually worked.
This is acceptable to me.</p>
<p>But Minecraft also uses per-axis interpolation.
Chunks of size 16x16x16 are generated from 8x8x4 volumes of noise.
My code was built with this in mind, and it's pretty much ready to go.
But oh no!
The crate I'm using to generate the noise values, <a href="https://crates.io/crates/simdnoise">simdnoise</a>, does not allow for per-axis frequency scaling.
A <a href="https://github.com/verpeteren/rust-simd-noise/pull/17">pull request</a> added the feature five years ago, but there have been no new releases since then!
Even though it would be simple, I'm still too lazy to pull the thing from github directly.
I've put it in the backlog for now, and hopefully we'll be able to experiment with that <em>eventually</em>.</p>

        </div>

                </div>
            <div class="pagination">
                <div class="pagination__buttons">
                    <span class="button next">
                        <a href="https://saskapult.github.io/page/2/">
                            <span class="button__text">Older posts</span>&nbsp;
                            <span class="button__icon">→</span>
                        </a>
                    </span>
                </div>
            </div>
        </div>
        
    </div>

    
    <footer class="footer">
        <div class="footer__inner">
                <div class="copyright">
                        <span>© 
    2025
 Powered by <a href="https://www.getzola.org/">Zola</a></span>
                    <span class="copyright-theme">
                        <span class="copyright-theme-sep">:: </span>
                        Theme: <a href="https://github.com/pawroman/zola-theme-terminimal/">Terminimal</a> by pawroman
                    </span>
                </div>
            </div>
    </footer>
    

</div>
</body>

</html>
